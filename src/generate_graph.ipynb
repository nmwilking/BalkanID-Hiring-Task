{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "import networkx as nx\n",
    "import json\n",
    "import arxiv\n",
    "from itertools import islice\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "papers = None\n",
    "with open(Config.REDUCED_JSON_PATH, 'r') as infile:\n",
    "    papers = json.load(infile)\n",
    "\n",
    "unarxiv = None\n",
    "with open(Config.UNARXIV_REDUCED_JSON_PATH, 'r') as infile:\n",
    "    unarxiv = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cursory density estimation\n",
    "\n",
    "l = set(papers.keys())\n",
    "found = {True: 0, False: 0}\n",
    "citing = set()\n",
    "cited = set()\n",
    "all_citations = set()\n",
    "for id, md in papers.items():\n",
    "    for ref in md['arxiv_bib_ids']:\n",
    "        all_citations.add(ref)\n",
    "        if ref in l:\n",
    "            found[True] += 1\n",
    "            citing.add(id)\n",
    "            cited.add(ref)\n",
    "        else:\n",
    "            found[False] += 1\n",
    "\n",
    "print(f'''This dataset contains {len(papers)} papers making {sum(found.values())} citations \\\n",
    "of {len(all_citations)} unique works, {found[True]} of which reference other papers in the dataset.\n",
    "{len(cited.intersection(citing))} papers in the dataset have both an incoming and outgoing citation in the set.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure papers is a subset of unarxiv so that unarxiv's keys can be used alone for node generation\n",
    "\n",
    "all([k in unarxiv for k in papers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "for id, data in unarxiv.items():\n",
    "    for bib_id in data['arxiv_bib_ids']:\n",
    "        # Protection against self-loops and external citations\n",
    "        if id != bib_id and bib_id in unarxiv:\n",
    "            g.add_edge(bib_id, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_directed_acyclic_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch publication dates for relevant papers\n",
    "\n",
    "def batched(iterable, n):\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(islice(it, n)):\n",
    "        yield batch\n",
    "\n",
    "client = arxiv.Client()\n",
    "id_strip_re = re.compile(r'(?P<id>.+)v\\d+$')\n",
    "for id_batch in batched(g.nodes, 500):\n",
    "    search = arxiv.Search(\n",
    "        id_list = list(id_batch)\n",
    "    )\n",
    "\n",
    "    for result in client.results(search):\n",
    "        id = result.get_short_id()\n",
    "        m = id_strip_re.match(id)\n",
    "        if m:\n",
    "            id = m.group('id')\n",
    "        if id in unarxiv:\n",
    "            unarxiv[id]['published'] = result.published\n",
    "        else:\n",
    "            print(f'{id} not found')\n",
    "            exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove edges that run counter to chronological order\n",
    "\n",
    "for src_id, dest_id in list(g.edges):\n",
    "    if unarxiv[src_id]['published'] > unarxiv[dest_id]['published']:\n",
    "        g.remove_edge(src_id, dest_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_directed_acyclic_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Config.GRAPH_BIN_PATH, 'wb') as outfile:\n",
    "    pickle.dump(g, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
